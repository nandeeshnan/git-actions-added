name: Deploy to AWS EKS

on:
  push:
    branches:
      - main  

jobs:
  deploy:
    runs-on: ubuntu-latest


    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Cache Terraform Binary
        id: cache-terraform
        uses: actions/cache@v4
        with:
          path: /usr/local/bin/terraform
          key: terraform-1.5.5

      - name: Install Terraform (if not cached)
        if: steps.cache-terraform.outputs.cache-hit != 'true'
          sudo apt-get update && sudo apt-get install -y unzip curl
          curl -fsSL -o terraform.zip https://releases.hashicorp.com/terraform/1.5.5/terraform_1.5.5_linux_amd64.zip
          unzip -o terraform.zip -d /usr/local/bin/
          chmod +x /usr/local/bin/terraform
          terraform --version

      - name: Login to Docker Hub
        run: |
          echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin

      - name: Build and Push Backend Image
        run: |
          docker build -t ${{ secrets.DOCKER_USERNAME }}/backend_recipe2:latest ./backend
          docker push ${{ secrets.DOCKER_USERNAME }}/backend_recipe2:latest

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Check if EKS Cluster Exists
        id: check-cluster
        run: |
          if aws eks describe-cluster --name my-eks-cluster --region us-east-1 > /dev/null 2>&1; then
            echo "CLUSTER_EXISTS=true" >> $GITHUB_ENV
          else
            echo "CLUSTER_EXISTS=false" >> $GITHUB_ENV
          fi

      - name: Initialize and Apply Terraform (Only if Cluster is Absent)
        if: env.CLUSTER_EXISTS == 'false'
        run: |
          cd terraform
          terraform init
          terraform apply -auto-approve

      - name: Configure kubectl
        run: |
          aws eks update-kubeconfig --region us-east-1 --name my-eks-cluster
          kubectl version --client

      - name: Deploy Backend Application to EKS
        run: |
          kubectl apply -f dep-ser/secrets.yml
          kubectl apply -f dep-ser/backe.yml
          kubectl rollout restart deployment backend -n default

      # - name: Verify Backend Deployment & Rollback on Failure
      #   run: |
      #     echo "Waiting for backend rollout..."
      #     if ! kubectl rollout status deployment backend -n default --timeout=30s; then
      #       echo "Backend rollout failed! Checking pod status..."
              
      #       POD_NAME=$(kubectl get pods -l app=backend -n default -o jsonpath='{.items[0].metadata.name}')
              
      #       IMAGE_STATUS=$(kubectl get pod $POD_NAME -n default -o jsonpath='{.status.containerStatuses[0].state.waiting.reason}')
            
      #       if [[ "$IMAGE_STATUS" == "ImagePullBackOff" || "$IMAGE_STATUS" == "ErrImagePull" || "$IMAGE_STATUS" == "CrashLoopBackOff" ]]; then
      #         echo "Detected ImagePullBackOff or ErrImagePull, rolling back..."
      #         kubectl rollout undo deployment backend -n default
      #         echo "Rollback triggered."
            
      #         echo "Deleting faulty pods..."
      #         kubectl delete pods -l app=backend -n default --force --grace-period=0
              
      #         echo "Waiting for fresh backend pods..."
      #         sleep 10  # Give Kubernetes some time
      #         kubectl get pods -n default
      #       fi
      #     fi



      - name: Wait for Backend Load Balancer IP
        run: |
          echo "Waiting for backend service to get an external IP..."
          for i in {1..30}; do
            BACKEND_IP=$(kubectl get svc backend -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
            if [[ ! -z "$BACKEND_IP" ]]; then
              echo "Backend Load Balancer is available at: http://$BACKEND_IP:8000"
              echo "BACKEND_IP=$BACKEND_IP" >> $GITHUB_ENV
              break
            fi
            echo "Still waiting... ($i/30)"
            sleep 10
          done

      - name: Update Frontend config.js with Backend IP
        run: |
          echo "window.BACKEND_URL = 'http://$BACKEND_IP:8000';" > frontend/config.js

      - name: Build and Push Updated Frontend Image
        run: |
          docker build -t ${{ secrets.DOCKER_USERNAME }}/frontend_recipe2:latest ./frontend
          docker push ${{ secrets.DOCKER_USERNAME }}/frontend_recipe2:latest

      - name: Deploy Frontend Application to EKS
        run: |
          kubectl apply -f dep-ser/fb-dep.yml
          kubectl rollout restart deployment frontend -n default

      - name: Verify Deployment
        run: |
          kubectl get pods -o wide
          kubectl get svc


# name: Deploy to AWS EKS

# on:
#   push:
#     branches:
#       - main  

# jobs:
#   deploy:
#     runs-on: ubuntu-latest

#     steps:
#       - name: Checkout Code
#         uses: actions/checkout@v4

#       - name: Cache Terraform Binary
#         id: cache-terraform
#         uses: actions/cache@v4
#         with:
#           path: /usr/local/bin/terraform
#           key: terraform-1.5.5

#       - name: Install Terraform (if not cached)
#         if: steps.cache-terraform.outputs.cache-hit != 'true'
#         run: |
#           sudo apt-get update && sudo apt-get install -y unzip curl
#           curl -fsSL -o terraform.zip https://releases.hashicorp.com/terraform/1.5.5/terraform_1.5.5_linux_amd64.zip
#           unzip -o terraform.zip -d /usr/local/bin/
#           chmod +x /usr/local/bin/terraform
#           terraform --version

#       - name: Login to Docker Hub
#         run: |
#           echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin

#       - name: Build and Push Backend Image
#         run: |
#           docker build -t ${{ secrets.DOCKER_USERNAME }}/backend_recipe2:latest ./backend
#           docker push ${{ secrets.DOCKER_USERNAME }}/backend_recipe2:latest

#       - name: Configure AWS Credentials
#         uses: aws-actions/configure-aws-credentials@v2
#         with:
#           aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
#           aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
#           aws-region: us-east-1

#       - name: Check if EKS Cluster Exists
#         id: check-cluster
#         run: |
#           if aws eks describe-cluster --name my-eks-cluster --region us-east-1 > /dev/null 2>&1; then
#             echo "CLUSTER_EXISTS=true" >> $GITHUB_ENV
#           else
#             echo "CLUSTER_EXISTS=false" >> $GITHUB_ENV
#           fi

#       - name: Initialize and Apply Terraform (Only if Cluster is Absent)
#         if: env.CLUSTER_EXISTS == 'false'
#         run: |
#           cd terraform
#           terraform init
#           terraform apply -auto-approve

#       - name: Configure kubectl
#         run: |
#           aws eks update-kubeconfig --region us-east-1 --name my-eks-cluster
#           kubectl version --client

#       - name: Deploy Backend Application to EKS
#         run: |
#           kubectl apply -f dep-ser/secrets.yml
#           kubectl apply -f dep-ser/backe.yml
#           kubectl rollout restart deployment backend -n default
#       - name: Verify Backend Deployment & Rollback on Failure
#         run: |
#           echo "Waiting for backend rollout..."
#           if ! kubectl rollout status deployment backend -n default --timeout=60s; then
#             echo "Backend rollout failed! Checking pod status..."
              
#             # Get pod name
#             POD_NAME=$(kubectl get pods -l app=backend -n default -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)

#             # Ensure POD_NAME is not empty
#             if [[ -z "$POD_NAME" ]]; then
#               echo "No faulty pod found. It might have already been removed."
#               exit 0
#             fi
              
#             # Get container status
#             IMAGE_STATUS=$(kubectl get pod $POD_NAME -n default -o jsonpath='{.status.containerStatuses[0].state.waiting.reason}' 2>/dev/null)
            
#             if [[ "$IMAGE_STATUS" == "ImagePullBackOff" || "$IMAGE_STATUS" == "ErrImagePull" || "$IMAGE_STATUS" == "CrashLoopBackOff" ]]; then
#               echo "Detected ImagePullBackOff or ErrImagePull, rolling back..."
#               kubectl rollout undo deployment backend -n default
#               echo "Rollback triggered."
            
#               # Double-check if pod still exists before trying to delete it
#               if kubectl get pod $POD_NAME -n default &>/dev/null; then
#                 echo "Deleting faulty pod: $POD_NAME..."
#                 kubectl delete pod $POD_NAME -n default --force --grace-period=0
#               else
#                 echo "Pod $POD_NAME no longer exists, skipping deletion."
#               fi
#             fi
#           fi


#       - name: Wait for Backend Load Balancer IP
#         run: |
#           echo "Waiting for backend service to get an external IP..."
#           for i in {1..30}; do
#             BACKEND_IP=$(kubectl get svc backend -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
#             if [[ ! -z "$BACKEND_IP" ]]; then
#               echo "Backend Load Balancer is available at: http://$BACKEND_IP:8000"
#               echo "BACKEND_IP=$BACKEND_IP" >> $GITHUB_ENV
#               break
#             fi
#             echo "Still waiting... ($i/30)"
#             sleep 10
#           done

#       - name: Update Frontend config.js with Backend IP
#         run: |
#           echo "window.BACKEND_URL = 'http://$BACKEND_IP:8000';" > frontend/config.js


#       - name: Build and Push Updated Frontend Image
#         run: |
#           docker build -t ${{ secrets.DOCKER_USERNAME }}/frontend_recipe2:latest ./frontend
#           docker push ${{ secrets.DOCKER_USERNAME }}/frontend_recipe2:latest

#       - name: Deploy Frontend Application to EKS
#         run: |
#           kubectl apply -f dep-ser/fb-dep.yml
#           kubectl rollout restart deployment frontend -n default

#       - name: Verify Deployment
#         run: |
#           kubectl get pods -o wide
#           kubectl get svc
